---
description: >-
  For those already familiar with LLM application tech stacks, this document
  serves as a shortcut to understand FusionWorks's unique advantages
---

<!-- # Features and Specifications

We adopt transparent policies around product specifications to ensure decisions are made based on complete understanding. Such transparency not only benefits your technical selection, but also promotes deeper comprehension within the community for active contributions. -->
<!-- 
### Project Basics

<table data-header-hidden><thead><tr><th width="341"></th><th></th></tr></thead><tbody><tr><td>Established</td><td>March 2023</td></tr><tr><td>Open Source License</td><td><a href="../../policies/open-source.md">Apache License 2.0 with commercial licensing</a></td></tr><tr><td>Official R&#x26;D Team</td><td>Over 10 full-time employees</td></tr><tr><td>Community Contributors</td><td>Over <a href="https://ossinsight.io/analyze/langgenius/FusionWorks#overview">290</a> people(As of Q2 2024)</td></tr><tr><td>Backend Technology</td><td>Python/Flask/PostgreSQL</td></tr><tr><td>Frontend Technology</td><td>Next.js</td></tr><tr><td>Codebase Size</td><td>Over 130,000 lines</td></tr><tr><td>Release Frequency</td><td>Average once per week</td></tr></tbody></table> -->

# Features and Specifications

<table data-header-hidden>
    <thead>
      <tr>
        <th width="258"></th>
        <th></th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>LLM Inference Engines</td>
        <td>
          FusionWorks supports over ten commercial models, including OpenAI and Anthropic, and can onboard new mainstream models within 48 hours. It also integrates seven MaaS vendors like Hugging Face and NVIDIA, and supports six local inference runtimes, such as Xorbits and OpenLLM.
        </td>
      </tr>
      <tr>
        <td>Multimodal Capabilities</td>
        <td>
          The platform supports ASR models and rich-text models up to GPT-4 specifications.
        </td>
      </tr>
      <tr>
        <td>Agentic Workflow Features</td>
        <td>
          FusionWorks offers a visual workflow orchestration interface with live-editing node debugging, modular DSL, and native code runtime, enabling the creation of complex and stable LLM applications. Supported nodes include LLM, Knowledge Retrieval, Question Classifier, IF/ELSE, CODE, Template, HTTP Request, and Tool.
        </td>
      </tr>
      <tr>
        <td>RAG Features</td>
        <td>
          The platform includes a visual knowledge base management interface, supporting snippet previews and recall testing. It offers various indexing methods (keywords, text vectors, LLM-assisted question-snippet models) and retrieval methods (keywords, text similarity matching, hybrid search).
        </td>
      </tr>
      <tr>
        <td>ETL Capabilities</td>
        <td>
          FusionWorks provides automated cleaning for TXT, Markdown, PDF, HTML, DOC, and CSV formats. It supports syncing Notion docs and webpages as knowledge bases.
        </td>
      </tr>
      <tr>
        <td>Vector Databases Supported</td>
        <td>
          FusionWorks supports multiple vector databases, including Qdrant, Weaviate, Zilliz/Milvus, Pgvector, and OpenSearch.
        </td>
      </tr>
      <tr>
        <td>Agent Technologies and Tooling Support</td>
        <td>
          The platform supports ReAct and Function Call agent technologies, invokes OpenAI Plugin standard tools, and can directly load OpenAPI Specification APIs. It includes over 40 built-in tools.
        </td>
      </tr>
      <tr>
        <td>Logging and Content Moderation</td>
        <td>
          FusionWorks supports detailed logging with annotations and provides content moderation using OpenAI Moderation or external APIs.
        </td>
      </tr>
      <tr>
        <td>Team Collaboration and API Specs</td>
        <td>
          The platform supports team collaboration with workspaces and multi-member management. It offers RESTful APIs covering most features.
        </td>
      </tr>
    </tbody>
  </table>

# Summary

FusionWorks offers a robust set of features, from comprehensive model support and multimodal capabilities to advanced workflow orchestration and flexible deployment options. It is designed to streamline AI application development and deployment, making it a versatile and powerful platform for various user needs.

For more detailed information, you can visit the original page [here](/en/README.md).
